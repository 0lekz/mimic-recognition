# Mimic Recognition

**Early Stage Ongoing Project** 

The idea behind this project is to build and deploy a fine-tuned **mimic (facial expression) recognition model** capable of detecting my own emotional state, such as **happy, sad, or neutral** from video frames in real-time.

Later, the model will be integrated into a lightweight python script to perform live emotion tracking and potentially trigger certain computer actions.

The **extended version** of the project aims to include **gesture (hand sign) recognition**, allowing real-time control or automation through simple gestures captured via webcam.
